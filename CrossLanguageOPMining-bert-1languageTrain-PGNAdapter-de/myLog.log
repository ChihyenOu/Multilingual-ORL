DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): s3.amazonaws.com:443
DEBUG:urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz HTTP/1.1" 200 0
INFO:driver.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz from cache at /home/chou/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9
INFO:driver.modeling:extracting archive file /home/chou/.pytorch_pretrained_bert/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9 to temp dir /tmp/tmprq42cdy6
INFO:driver.modeling:Model config {
  "adapter_act": "gelu",
  "adapter_initializer_range": 0.0002,
  "adapter_prediction": "average",
  "adapter_size": 256,
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "language_drop_rate": 0.2,
  "language_emb_dropout": 0.1,
  "language_emb_size": 32,
  "language_features": "syntax_knn+phonology_knn+inventory_knn",
  "max_position_embeddings": 512,
  "nl_project": 289,
  "num_adapters": 1,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_language_features": "syntax_knn+phonology_knn+inventory_knn",
  "num_languages": 2,
  "one_hot": false,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "use_adapter": true,
  "use_language_emb": true,
  "vocab_size": 119547
}

INFO:driver.modeling:Weights of BertModel not initialized from pretrained model: ['bert.encoder.layer.0.attention.output.adapter.down_W', 'bert.encoder.layer.0.attention.output.adapter.down_b', 'bert.encoder.layer.0.attention.output.adapter.up_W', 'bert.encoder.layer.0.attention.output.adapter.up_b', 'bert.encoder.layer.0.output.adapter.down_W', 'bert.encoder.layer.0.output.adapter.down_b', 'bert.encoder.layer.0.output.adapter.up_W', 'bert.encoder.layer.0.output.adapter.up_b', 'bert.encoder.layer.1.attention.output.adapter.down_W', 'bert.encoder.layer.1.attention.output.adapter.down_b', 'bert.encoder.layer.1.attention.output.adapter.up_W', 'bert.encoder.layer.1.attention.output.adapter.up_b', 'bert.encoder.layer.1.output.adapter.down_W', 'bert.encoder.layer.1.output.adapter.down_b', 'bert.encoder.layer.1.output.adapter.up_W', 'bert.encoder.layer.1.output.adapter.up_b', 'bert.encoder.layer.2.attention.output.adapter.down_W', 'bert.encoder.layer.2.attention.output.adapter.down_b', 'bert.encoder.layer.2.attention.output.adapter.up_W', 'bert.encoder.layer.2.attention.output.adapter.up_b', 'bert.encoder.layer.2.output.adapter.down_W', 'bert.encoder.layer.2.output.adapter.down_b', 'bert.encoder.layer.2.output.adapter.up_W', 'bert.encoder.layer.2.output.adapter.up_b', 'bert.encoder.layer.3.attention.output.adapter.down_W', 'bert.encoder.layer.3.attention.output.adapter.down_b', 'bert.encoder.layer.3.attention.output.adapter.up_W', 'bert.encoder.layer.3.attention.output.adapter.up_b', 'bert.encoder.layer.3.output.adapter.down_W', 'bert.encoder.layer.3.output.adapter.down_b', 'bert.encoder.layer.3.output.adapter.up_W', 'bert.encoder.layer.3.output.adapter.up_b', 'bert.encoder.layer.4.attention.output.adapter.down_W', 'bert.encoder.layer.4.attention.output.adapter.down_b', 'bert.encoder.layer.4.attention.output.adapter.up_W', 'bert.encoder.layer.4.attention.output.adapter.up_b', 'bert.encoder.layer.4.output.adapter.down_W', 'bert.encoder.layer.4.output.adapter.down_b', 'bert.encoder.layer.4.output.adapter.up_W', 'bert.encoder.layer.4.output.adapter.up_b', 'bert.encoder.layer.5.attention.output.adapter.down_W', 'bert.encoder.layer.5.attention.output.adapter.down_b', 'bert.encoder.layer.5.attention.output.adapter.up_W', 'bert.encoder.layer.5.attention.output.adapter.up_b', 'bert.encoder.layer.5.output.adapter.down_W', 'bert.encoder.layer.5.output.adapter.down_b', 'bert.encoder.layer.5.output.adapter.up_W', 'bert.encoder.layer.5.output.adapter.up_b', 'bert.encoder.layer.6.attention.output.adapter.down_W', 'bert.encoder.layer.6.attention.output.adapter.down_b', 'bert.encoder.layer.6.attention.output.adapter.up_W', 'bert.encoder.layer.6.attention.output.adapter.up_b', 'bert.encoder.layer.6.output.adapter.down_W', 'bert.encoder.layer.6.output.adapter.down_b', 'bert.encoder.layer.6.output.adapter.up_W', 'bert.encoder.layer.6.output.adapter.up_b', 'bert.encoder.layer.7.attention.output.adapter.down_W', 'bert.encoder.layer.7.attention.output.adapter.down_b', 'bert.encoder.layer.7.attention.output.adapter.up_W', 'bert.encoder.layer.7.attention.output.adapter.up_b', 'bert.encoder.layer.7.output.adapter.down_W', 'bert.encoder.layer.7.output.adapter.down_b', 'bert.encoder.layer.7.output.adapter.up_W', 'bert.encoder.layer.7.output.adapter.up_b', 'bert.encoder.layer.8.attention.output.adapter.down_W', 'bert.encoder.layer.8.attention.output.adapter.down_b', 'bert.encoder.layer.8.attention.output.adapter.up_W', 'bert.encoder.layer.8.attention.output.adapter.up_b', 'bert.encoder.layer.8.output.adapter.down_W', 'bert.encoder.layer.8.output.adapter.down_b', 'bert.encoder.layer.8.output.adapter.up_W', 'bert.encoder.layer.8.output.adapter.up_b', 'bert.encoder.layer.9.attention.output.adapter.down_W', 'bert.encoder.layer.9.attention.output.adapter.down_b', 'bert.encoder.layer.9.attention.output.adapter.up_W', 'bert.encoder.layer.9.attention.output.adapter.up_b', 'bert.encoder.layer.9.output.adapter.down_W', 'bert.encoder.layer.9.output.adapter.down_b', 'bert.encoder.layer.9.output.adapter.up_W', 'bert.encoder.layer.9.output.adapter.up_b', 'bert.encoder.layer.10.attention.output.adapter.down_W', 'bert.encoder.layer.10.attention.output.adapter.down_b', 'bert.encoder.layer.10.attention.output.adapter.up_W', 'bert.encoder.layer.10.attention.output.adapter.up_b', 'bert.encoder.layer.10.output.adapter.down_W', 'bert.encoder.layer.10.output.adapter.down_b', 'bert.encoder.layer.10.output.adapter.up_W', 'bert.encoder.layer.10.output.adapter.up_b', 'bert.encoder.layer.11.attention.output.adapter.down_W', 'bert.encoder.layer.11.attention.output.adapter.down_b', 'bert.encoder.layer.11.attention.output.adapter.up_W', 'bert.encoder.layer.11.attention.output.adapter.up_b', 'bert.encoder.layer.11.output.adapter.down_W', 'bert.encoder.layer.11.output.adapter.down_b', 'bert.encoder.layer.11.output.adapter.up_W', 'bert.encoder.layer.11.output.adapter.up_b']
